# llama
1. https://ai.meta.com/blog/meta-llama-3/
2. https://about.fb.com/news/2024/04/meta-ai-assistant-built-with-llama-3/

# 参数规模
1. 8B
2. 70B

# 数据处理
1. 15T，是Llama 2所用数据集的七倍。
2. 数据过滤管道使用包括启发式过滤器、NSFW过滤器、语义去重方法和文本分类器来预测数据质量。
3. 使用Llama 2为驱动Llama 3的文本质量分类器生成训练数据。

# 模型架构
Llama 3使用了一个拥有128K个词汇的分词器，这种分词器对语言的编码效率更高，从而显著提高了模型性能。为了提高Llama 3模型的推理效率，我们在8B和70B大小的模型中都采用了分组查询注意力（GQA）。我们训练模型使用的是8,192个词元的序列，并使用掩码确保自注意力不会跨越文档边界。
# 扩大预训练
1. 对于一个8B参数模型，Chinchilla最优的训练计算量相当于约200B个词元，但我们发现即使在模型训练了两个数量级更多的数据之后，模型性能仍在继续提高。
2. 三种类型的并行化：数据并行化、模型并行化和流水线并行化。
3. 最有效的实现在16K个GPU上同时训练时，每个GPU的计算利用率超过400 TFLOPS。
4. 在两个定制的24K GPU集群上进行了训练运行。
5. 为了最大化GPU的运行时间，开发了一种先进的新训练栈，该栈自动化错误检测、处理和维护。
6. 我们还大大提高了我们的硬件可靠性和检测机制，以检测静默数据损坏，并开发了新的可扩展存储系统，以减少检查点和回滚的开销。这些改进使得整体有效的训练时间超过95%。
7. 总体而言，与Llama 2相比，这些改进将Llama 3的训练效率提高了约三倍。

# 指令微调
1. 后训练的方法是监督式微调（SFT）、拒绝采样、近端策略优化（PPO）和直接策略优化（DPO）的结合。
2. 如果你向模型提出一个它难以回答的推理问题，模型有时会产生正确的推理轨迹：模型知道如何产生正确的答案，但它不知道如何选择它。 通过PPO和DPO从首选排名中学习，也极大地提高了Llama 3在推理和编码任务上的性能。

# 构建Llama3
1. 我们的愿景是使开发者能够自定义 Llama 3，以支持相关用例，并使其更容易采用最佳实践并改进开放生态系统。

2. 在这次发布中，我们提供了新的信任和安全工具，包括更新的组件，既包含 Llama Guard 2 也包含 Cybersec Eval 2，以及引入了 Code Shield——一个用于过滤由大型语言模型生成的不安全代码的推理时保护栏。

3. 我们还与 torchtune 共同开发了 Llama 3，这是一个全新的 PyTorch 原生库，用于轻松编写、微调和试验大型语言模型。

4. torchtune 提供了高效节省内存的、可深度定制的训练配方，完全基于 PyTorch 编写。该库与诸如 Hugging Face、Weights & Biases 和 EleutherAI 等流行平台集成，并且支持 Executorch，使得高效的推理能在各种移动和边缘设备上运行。

5. 从提示工程到使用 Llama 3 与 LangChain，我们提供了一个全面的入门指南，指导您从下载 Llama 3 到在您的生成式 AI 应用中的大规模部署。

# 系统级别的责任化方法
1. Llama Guard模型旨在成为提示和响应安全性的基础，并且可以根据应用需求轻松微调以创建新的分类法。作为起点，新的Llama Guard 2使用了最近宣布的MLCommons分类法，以支持这一重要领域行业标准的出现。此外，CyberSecEval 2在其前身的基础上增加了措施，评估了语言模型允许滥用其代码解释器、攻击性网络安全能力以及对提示注入攻击的易感性（在我们的技术论文中了解更多）。最后，我们引入了Code Shield，它增加了对LLMs产生的不安全代码在推理时的过滤支持。这提供了对不安全代码建议的风险缓解、代码解释器滥用预防和安全命令执行。

2. 负责任使用指南（RUG）
# 大规模部署Llama 3
1. Llama 3 很快将在所有主要平台上可用，包括云服务提供商、模型API提供商等。
2. 我们的基准测试显示，分词器提供了改进的令牌效率，与Llama 2相比，生成的令牌最多减少了15%。此外，分组查询注意力（GQA）现在也已经添加到Llama 3 8B中。结果，我们观察到尽管模型比Llama 2 7B多出10亿参数，但由于改进的分词器效率和GQA的加入，推理效率保持与Llama 2 7B相当。
3. 要了解如何利用所有这些能力，可以查看Llama Recipes，其中包含了我们所有的开源代码，这些代码可以用于从微调到部署到模型评估的所有事情。

# Llama 3的未来发展
1. 我们最大的模型超过400B参数仍在训练中。在接下来的几个月里，我们将发布多个具有新功能的模型，包括多模态性、能够用多种语言对话、更长的上下文窗口以及更强大的整体能力。一旦完成Llama 3的训练，我们还将发布一份详细的研究论文。

# 重点机构
Llama 3 模型很快将在 AWS、Databricks、Google Cloud、Hugging Face、Kaggle、IBM WatsonX、Microsoft Azure、NVIDIA NIM 和 Snowflake 上提供，并得到 AMD、AWS、Dell、Intel、NVIDIA 和 Qualcomm 提供的硬件平台支持。我们致力于以负责任的方式开发 Llama 3，并提供各种资源帮助其他人也能负责任地使用它。这包括推出新的信任和安全工具，如 Llama Guard 2、Code Shield 和 CyberSec Eval 2。

# 在线体验
1. https://llama3.replicate.dev/
2. https://chat.tune.app/
